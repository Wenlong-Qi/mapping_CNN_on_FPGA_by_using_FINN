{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "import struct\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quant(Vx, Q, RQM):\n",
    "    return round(Q * Vx) - RQM\n",
    "\n",
    "\n",
    "def ListQuant(data_list, quant_bits):\n",
    "    \n",
    "    data_min = min(data_list)\n",
    "    data_max = max(data_list)\n",
    "\n",
    "    \n",
    "    Q = ((1 << quant_bits) - 1) * 1.0 / (data_max - data_min)\n",
    "    RQM = (int)(round(Q*data_min))\n",
    "\n",
    "    \n",
    "    quant_data_list = []\n",
    "    for x in data_list:\n",
    "        quant_data = Quant(x, Q, RQM)\n",
    "        quant_data_list.append(quant_data)\n",
    "    quant_data_list = np.array(quant_data_list)\n",
    "    return (Q, RQM, quant_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "class ReadDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.data_info = pd.read_csv(csv_path, header = None)\n",
    "        self.ecg_arr = np.asarray(self.data_info.iloc[:, 0]) # read csv filename\n",
    "        self.label_arr = preprocessing.LabelEncoder().fit_transform(np.asarray(self.data_info.iloc[:, 1])) # read labels     \n",
    "        self.data_len = len(self.data_info.index) # calculate length\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        single_ecg_name = self.ecg_arr[index] # get filename\n",
    "        \n",
    "        ecg_raw_data = (open(os.path.join('./simplified_atrial_fibrillation/',single_ecg_name),'rb')).read() # read ecg file\n",
    "        ecg_data = []\n",
    "        for t in (range(0,len(ecg_raw_data),4)):\n",
    "            ecg_data.append((struct.unpack('h',ecg_raw_data[t:t+2]))[0])\n",
    "            \n",
    "        ecg_Q, ecg_RQM, ecg_Quantdata = ListQuant(ecg_data,quant_bits=8) #quant to 8 bit\n",
    "        \n",
    "        # 1D to 2D, and divide 255\n",
    "        data_resize=ecg_Quantdata\n",
    "        data_resize=np.float32(np.trunc(data_resize))\n",
    "        #data_resize=np.float32((np.trunc(data_resize))/255.0)\n",
    "        \n",
    "        data_resize.resize((73,73),refcheck=False) # 74*74=5476>5250\n",
    "        #data_resize = np.expand_dims(data_resize, axis = 1)\n",
    "        data_resize = np.expand_dims(data_resize, axis = 0)\n",
    "        \n",
    "        data = data_resize\n",
    "        \n",
    "        label = self.label_arr[index]\n",
    "        return(data, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./simplified_atrial_fibrillation/test.csv\"\n",
    "read_dataset = ReadDataset(csv_path)\n",
    "test_loader = DataLoader(dataset=read_dataset, batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[153., 152., 154.,  ..., 166., 163., 162.],\n",
      "         [161., 160., 162.,  ..., 128., 149., 156.],\n",
      "         [168., 172., 179.,  ..., 184., 181., 182.],\n",
      "         ...,\n",
      "         [190., 187., 191.,  ..., 222., 248., 205.],\n",
      "         [100.,  27.,  68.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]])\n",
      "132.0\n",
      "torch.Size([512, 1, 73, 73])\n",
      "tensor(0)\n",
      "torch.Size([1, 73, 73])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "cnt = 0\n",
    "\n",
    "for m, (X_test, y_test) in enumerate(test_loader): \n",
    "    if cnt>=1: \n",
    "        break  \n",
    "    i = random.randint(0,len(X_test))\n",
    "    print((X_test[i]))\n",
    "    output_txt = X_test[i]\n",
    "    print(np.median(X_test))\n",
    "    #print(min(X_train[i][0]))\n",
    "    print((X_test.shape))\n",
    "    print(y_test[i])\n",
    "    output_label = y_test[i]\n",
    "    print(X_test[i].shape)\n",
    "    #print(y_test.shape)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[153., 152., 154.,  ..., 166., 163., 162.],\n",
       "         [161., 160., 162.,  ..., 128., 149., 156.],\n",
       "         [168., 172., 179.,  ..., 184., 181., 182.],\n",
       "         ...,\n",
       "         [190., 187., 191.,  ..., 222., 248., 205.],\n",
       "         [100.,  27.,  68.,  ...,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantMaxPool2d, QuantLinear,QuantDropout,QuantReLU,QuantHardTanh\n",
    "from brevitas.core.quant import QuantType, BinaryQuant, TernaryQuant\n",
    "from brevitas.core.scaling import ConstScaling\n",
    "from brevitas.quant import SignedTernaryActPerTensorConst,SignedBinaryActPerTensorConst,Int8ActPerTensorFloatMinMaxInit\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to 1D\n",
    "\n",
    "class ECG_AF_2D(nn.Module):\n",
    "    def __init__(self,input_size,num_classes,weight_bit_width,act_bit_width):\n",
    "        super(ECG_AF_2D,self).__init__()\n",
    "        \n",
    "        self.cnn_1 = QuantConv2d(in_channels=input_size,out_channels=6,kernel_size=3,\n",
    "                                padding=0, stride=2,\n",
    "                                bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_1 = nn.BatchNorm2d(6)\n",
    "        self.relu_1 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size=2,stride=None)\n",
    "        \n",
    "        self.cnn_d2 = QuantConv2d(in_channels=6,out_channels=6,kernel_size=3,\n",
    "                                 padding=0,groups=6,\n",
    "                                 bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_d2 = nn.BatchNorm2d(6)\n",
    "        self.relu_d2 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.cnn_2 = QuantConv2d(in_channels=6,out_channels=5,kernel_size=1,\n",
    "                                padding=0,\n",
    "                                bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_2 = nn.BatchNorm2d(5)\n",
    "        self.relu_2 = QuantReLU(bit_width=act_bit_width)\n",
    "        \n",
    "        self.cnn_d3 = QuantConv2d(in_channels=5,out_channels=5,kernel_size=3,\n",
    "                                 padding=1,groups=5,\n",
    "                                 bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_d3 = nn.BatchNorm2d(5)\n",
    "        self.relu_d3 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.cnn_3 = QuantConv2d(in_channels=5,out_channels=5,kernel_size=1,\n",
    "                                padding=0,\n",
    "                                bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_3 = nn.BatchNorm2d(5)\n",
    "        self.relu_3 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size=2,stride=None) \n",
    "     \n",
    "        self.cnn_d4 = QuantConv2d(in_channels=5,out_channels=5,kernel_size=3,\n",
    "                                 padding=0,groups=5,\n",
    "                                 bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_d4 = nn.BatchNorm2d(5)\n",
    "        self.relu_d4 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.cnn_4 = QuantConv2d(in_channels=5,out_channels=3,kernel_size=1,\n",
    "                                padding=0,\n",
    "                                bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_4 = nn.BatchNorm2d(3)\n",
    "        self.relu_4 = QuantReLU(bit_width=act_bit_width)\n",
    "        self.maxpool_4 = nn.MaxPool2d(kernel_size=3,stride=None)\n",
    "        \n",
    "        self.drop = QuantDropout(p=0.5)\n",
    "        self.dense =QuantLinear(2*2*3,num_classes,bias=False,weight_bit_width=weight_bit_width)\n",
    "        self.bn_5 = nn.BatchNorm1d(2)\n",
    "        self.relu_5 = QuantReLU(bit_width=act_bit_width)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.relu_1(self.bn_1(self.cnn_1(x)))\n",
    "        x = self.maxpool_1(x)\n",
    "            \n",
    "        x = self.relu_d2(self.bn_d2(self.cnn_d2(x)))\n",
    "        x = self.relu_2(self.bn_2(self.cnn_2(x)))\n",
    "\n",
    "        x = self.relu_d3(self.bn_d3(self.cnn_d3(x)))\n",
    "        x = self.relu_3(self.bn_3(self.cnn_3(x)))\n",
    "        x = self.maxpool_3(x)\n",
    "        \n",
    "        x = self.relu_d4(self.bn_d4(self.cnn_d4(x)))\n",
    "        x = self.relu_4(self.bn_4(self.cnn_4(x)))\n",
    "        x = self.maxpool_4(x)\n",
    "            \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.drop(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.bn_5(x)\n",
    "        x = self.relu_5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 # 3 input layers for RGB image\n",
    "num_classes = 2\n",
    "weight_bit_width = 2\n",
    "act_bit_width = 2\n",
    "\n",
    "original_model = ECG_AF_2D(input_size=input_size,num_classes=num_classes,\n",
    "                            weight_bit_width=weight_bit_width,act_bit_width=act_bit_width)\n",
    "state_dict = torch.load('./multi_model/relu_without_ternarize.pth')\n",
    "original_model.load_state_dict(state_dict)\n",
    "original_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 73, 73])\n",
      "input: tensor([[[[0.6000, 0.5961, 0.6039,  ..., 0.6510, 0.6392, 0.6353],\n",
      "          [0.6314, 0.6275, 0.6353,  ..., 0.5020, 0.5843, 0.6118],\n",
      "          [0.6588, 0.6745, 0.7020,  ..., 0.7216, 0.7098, 0.7137],\n",
      "          ...,\n",
      "          [0.7451, 0.7333, 0.7490,  ..., 0.8706, 0.9725, 0.8039],\n",
      "          [0.3922, 0.1059, 0.2667,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
      "Label_true: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = output_txt/255.0\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "print(input_tensor.shape)\n",
    "print(\"input:\",input_tensor)\n",
    "print(\"Label_true:\",output_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_golden: [[1.0797518 0.       ]]\n",
      "Label_pred: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "output_golden = original_model.forward(input_tensor).detach().numpy()\n",
    "print(\"output_golden:\",output_golden)\n",
    "output_golden_label = torch.from_numpy(output_golden)\n",
    "output_golden_label = torch.max(output_golden_label,1)[1]\n",
    "print(\"Label_pred:\",output_golden_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat test file if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt = output_txt.squeeze()\n",
    "output_txt = (np.array(output_txt)).astype(int)\n",
    "np.savetxt('./test_data/test_5.txt',output_txt, fmt=\"%x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "import onnx.numpy_helper as nph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 73, 73])\n"
     ]
    }
   ],
   "source": [
    "input_test_1 = output_txt\n",
    "input_test_1 = input_test_1.unsqueeze(0)\n",
    "print(input_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [[[[153. 152. 154. ... 166. 163. 162.]\n",
      "   [161. 160. 162. ... 128. 149. 156.]\n",
      "   [168. 172. 179. ... 184. 181. 182.]\n",
      "   ...\n",
      "   [190. 187. 191. ... 222. 248. 205.]\n",
      "   [100.  27.  68. ...   0.   0.   0.]\n",
      "   [  0.   0.   0. ...   0.   0.   0.]]]]\n",
      "Label_true: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "input_numpy = (input_test_1.numpy()).astype(np.float32)#.tolist()\n",
    "input_dict = {\"global_in\": input_numpy}\n",
    "print(\"input:\",input_numpy)\n",
    "print(\"Label_true:\",output_label)\n",
    "\n",
    "model_for_sim = ModelWrapper(\"./test/ECG_AF_2D_w2a2_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Simulation: Label_pred [[0]]\n"
     ]
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "output_dict = oxe.execute_onnx(model_for_sim, input_dict)\n",
    "output_pysim = output_dict[list(output_dict.keys())[0]]\n",
    "print(\"Results for Simulation: Label_pred\",output_pysim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
